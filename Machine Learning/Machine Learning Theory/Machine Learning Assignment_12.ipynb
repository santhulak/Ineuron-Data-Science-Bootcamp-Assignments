{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997b1325",
   "metadata": {},
   "source": [
    "1. What is prior probability? Give an example.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f281c3",
   "metadata": {},
   "source": [
    "Prior probability refers to the probability assigned to an event or hypothesis before any new evidence or data is taken into account. It is typically based on past experience, intuition, or other relevant information.\n",
    "\n",
    "For example, suppose we are trying to determine the probability that a person has a certain medical condition based on their age and gender. We may have prior knowledge about the prevalence of the condition in different age and gender groups, which we can use as prior probabilities. These prior probabilities can then be updated with new data, such as the results of a medical test, to obtain a more accurate estimate of the person's probability of having the condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2258e6b",
   "metadata": {},
   "source": [
    "2. What is posterior probability? Give an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc12e9",
   "metadata": {},
   "source": [
    "Posterior probability is the probability of an event or hypothesis given new evidence or information. \n",
    "\n",
    "For example, let's say a doctor knows that 5% of patients who have a certain symptom have a particular disease. If a patient comes in with that symptom, the prior probability of them having the disease is 5%. However, if the doctor runs a test and the result is positive for the disease, the posterior probability of the patient having the disease increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c139c116",
   "metadata": {},
   "source": [
    "3. What is likelihood probability? Give an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329b0a9",
   "metadata": {},
   "source": [
    "Likelihood probability is the probability of observing the data given a particular hypothesis or parameter value. It is a function of the parameter(s) given the data.\n",
    "\n",
    "For example, suppose we have a coin, and we want to determine whether it is a fair coin (i.e., it has an equal chance of landing heads or tails). We flip the coin 10 times and observe 6 heads and 4 tails. We can use the likelihood function to find the probability of observing these results given that the coin is fair. The likelihood function in this case would be the binomial distribution with n=10 and p=0.5:\n",
    "\n",
    "L(p|data) = P(data|p) = (10 choose 6) * 0.5^6 * 0.5^4 = 0.205\n",
    "\n",
    "This tells us the probability of observing 6 heads and 4 tails in 10 flips of a fair coin. We can then compare this to the likelihood of other parameter values, such as p=0.6 or p=0.4, to determine which value of p is most likely given the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eacce2",
   "metadata": {},
   "source": [
    "4. What is Naïve Bayes classifier? Why is it named so?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be19883",
   "metadata": {},
   "source": [
    "Naïve Bayes classifier is a probabilistic classification algorithm that is used to classify data into categories based on prior knowledge of the likelihood of events. It is based on Bayes' theorem and assumes that the features in a dataset are independent of each other, hence the name \"Naïve.\"\n",
    "\n",
    "For example, if we have a dataset of emails and we want to classify them as spam or not spam, we can use the Naïve Bayes classifier to calculate the probability of each word appearing in a spam email and the probability of each word appearing in a non-spam email. We can then use these probabilities to classify new emails as spam or not spam based on the words they contain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ccd671",
   "metadata": {},
   "source": [
    "5. What is optimal Bayes classifier?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200181e2",
   "metadata": {},
   "source": [
    "The optimal Bayes classifier is a classification algorithm that uses the Bayes theorem to predict the class of an input sample. It is an ideal or theoretical classifier that can achieve the lowest possible error rate, known as the Bayes error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec062778",
   "metadata": {},
   "source": [
    "6. Write any two features of Bayesian learning methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad5aa7",
   "metadata": {},
   "source": [
    "Two features of Bayesian learning methods are:\n",
    "\n",
    "Bayesian learning methods take into account prior knowledge or beliefs about the data before updating them based on new evidence or data. This makes them particularly useful in situations where there is limited data available, as the prior can help guide the learning process.\n",
    "\n",
    "Bayesian learning methods can also provide uncertainty estimates for their predictions. This is because they treat model parameters as random variables and use probability distributions to represent their uncertainty. By taking into account this uncertainty, Bayesian methods can provide more robust predictions that are less prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d91de",
   "metadata": {},
   "source": [
    "7. Define the concept of consistent learners.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361b46a",
   "metadata": {},
   "source": [
    "In machine learning, a consistent learner is a learning algorithm that can learn the true target function of the given problem, given enough data and computational resources. A consistent learner is guaranteed to converge to the true target function as the amount of training data approaches infinity. This means that the learner's predictions become more accurate as more data is provided for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0508775",
   "metadata": {},
   "source": [
    "8. Write any two strengths of Bayes classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1540fb6e",
   "metadata": {},
   "source": [
    "Here are two strengths of the Bayes classifier:\n",
    "\n",
    "Effective for small training sets: Bayes classifier can work effectively even when the size of the training set is small. This is because it is based on probabilistic models, which allow for making predictions with limited data.\n",
    "\n",
    "Handles irrelevant features: Bayes classifier is less affected by irrelevant features in the data. This is because it estimates the probability of each class given the data, and ignores the irrelevant features in the process. This makes it more robust to noisy and irrelevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f634331",
   "metadata": {},
   "source": [
    "9. Write any two weaknesses of Bayes classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0576b",
   "metadata": {},
   "source": [
    "Here are two weaknesses of the Bayes classifier:\n",
    "\n",
    "Naive assumption: One of the main weaknesses of the Bayes classifier is its assumption of independence among the features. In many real-world problems, features can be correlated, and this assumption may not hold true. When the assumption of independence is violated, the classifier may produce less accurate results.\n",
    "\n",
    "Sensitivity to prior probabilities: The Bayes classifier is sensitive to the prior probabilities of the classes. If the prior probabilities are not accurately estimated, then the classifier may produce poor results. In some cases, the prior probabilities may be unknown or difficult to estimate, which can lead to uncertainty in the classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f3751",
   "metadata": {},
   "source": [
    "10. Explain how Naïve Bayes classifier is used for\n",
    "\n",
    "        1. Text classification\n",
    "\n",
    "       Naïve Bayes classifier is a popular algorithm used for text classification tasks such as sentiment analysis, spam detection, and topic categorization. In text classification, each document is represented as a bag-of-words model, where the order of words is not considered, and the occurrence of each word in the document is counted. The Naïve Bayes classifier then uses the probability of each word given a class label to compute the probability of a document belonging to that class.\n",
    "\n",
    "For example, in sentiment analysis, the Naïve Bayes classifier is trained on a dataset of labeled reviews where each review is assigned a sentiment label (positive or negative). The algorithm learns the conditional probabilities of each word given the positive and negative sentiment labels. When a new review is provided, the Naïve Bayes classifier computes the probability of the review belonging to each class label using the conditional probabilities of the words in the review. The review is then assigned the class label with the highest probability.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04f8a38",
   "metadata": {},
   "source": [
    " 2. Spam filtering\n",
    "\n",
    "Naïve Bayes classifier is a popular machine learning algorithm used for spam filtering. The basic idea is to classify email messages as spam or non-spam (also called ham) based on their content.\n",
    "\n",
    "The Naïve Bayes classifier works by calculating the probability of an email being spam or ham based on the presence or absence of certain words or phrases in the email message. This is done by first training the classifier on a set of pre-labeled emails, with some labeled as spam and some labeled as ham. Once the classifier is trained, it can be used to classify new emails as either spam or ham.  The classifier then assigns the email to the class with the higher probability.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ceb98c",
   "metadata": {},
   "source": [
    " 3. Market sentiment analysis\n",
    " \n",
    " Naïve Bayes classifier is a popular method for market sentiment analysis. It works by analyzing text data (such as social media posts, news articles, or online reviews) to determine the sentiment or opinion of the writer regarding a particular product, service, or brand.\n",
    "\n",
    "The Naïve Bayes classifier assumes that the features (words or phrases) in the text data are independent of each other, which makes the calculation of probabilities simpler. The classifier first creates a training dataset with labeled examples of positive and negative sentiment, and then uses this dataset to calculate the conditional probability of each feature given the class (positive or negative sentiment). When new data is presented to the classifier, it calculates the conditional probabilities of the features given each class and multiplies them together to obtain the likelihoods.  The class with the highest posterior probability is then assigned to the new data point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
